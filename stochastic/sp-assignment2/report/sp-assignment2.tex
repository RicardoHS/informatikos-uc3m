\documentclass[11pt, a4paper]{article}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}

\usepackage{amsmath,amssymb,amsthm,amsfonts,graphicx,float,fullpage,booktabs,bm} 
\usepackage[colorlinks,citecolor=blue,bookmarks=true]{hyperref}
\hypersetup{linkcolor=blue}
\usepackage{cleveref}
% Code listings
\usepackage{minted}
\usepackage{listings}
\usepackage{caption}
\usemintedstyle[python]{manni}
\usemintedstyle[R]{manni}
\usepackage{todonotes}
\usepackage{subcaption}
\usepackage[backend = bibtex]{biblatex}
\addbibresource{bibliography.bib}


\title{\vspace{-8ex} \huge \bfseries Stochastic Processes\\
	\LARGE \normalfont \textsc{Assignment Two} \vspace{-2ex}}
\author{\bfseries Santiago Alfonso Raposo Briceño - 100414456 \\
	\bfseries Javier Martínez Llamas - 100392684\\
	\bfseries Ricardo Hortelano Sánchez - 100418220}
\date{\vspace{-5ex}} % Remove space where date would be.

\begin{document}
	\maketitle
	\hrule

\section{Exercise 1}

The account selected for the extraction of the tweets is \textit{@realmadrid} since it has a constant number of retweets (RT), not extremely high, allowing us to measure the counting process in a reasonable time space. 
Although library \textit{rtweet} obtains information about the retweets and their time stamps it is worth mentioning that the results detailed here do not reflect the actual behaviour of the account since retweet count is limited to 100.

\subsection{Use descriptive statistics and graphics to explore the retweets data set in terms of the number of retweets by time and the time between retweets. Does it fit the hypothesis of a Poisson process?}

We know that a Poisson process is a counting process related with the Poisson and Exponential distributions. 
Being a counting process a stochastic process $\mathbf{N} = \{ N_t, t \geq 0 \}$ satisfying:
\begin{itemize}
	\item $N_t=0$
	\item $N_t$ is integer valued
	\item For $s<t, N_s \leq N_t$
	\item For $s<t, N_t - N_s$ represents the number of events that occur in the time intervals (s, t]
\end{itemize}

When plotting the tweet with maximum retweets (limited) and all the tweets we can see the behaviour of the retweet counting process.

\begin{figure}[H]
	\centering
	\begin{subfigure}{.5\textwidth}
		\centering
		\input{./figures/maxRTcurve.tex}
		\caption{Maximum RT Tweet Distribution}
		\label{fig:rtMax}
	\end{subfigure}%
	\begin{subfigure}{.5\textwidth}
		\centering
		\vspace*{-3em}
		\input{./figures/allRTcurve.tex}
		\vspace*{-1.4em}
		\caption{All Tweets Distributions}
		\label{fig:rtAll}
	\end{subfigure}
\end{figure}

Each retweet counting process is defined by a time series, measuring the time for the next count (in minutes) since the creation of the tweet. 
That is, starting at $N_t=0, t=0$ the arrival times $s$ increases the count by 1 unit, fulfilling the condition $s<t, N_s \leq N_t$. Moreover, for any time $s<t$ the number of retweets in the interval $(s, t]$ is the difference $N_t -N_s$. 

Assuming that, if a user undoes a retweet, when acquiring the dataset the former time of retweet it is no longer recorded, the count can only increase and never decrease. 
The real model does not hold this assumption since this restriction is imposed by the internal functioning of Twitter and its API. 

i.e. The following sequence of times would define a retweet counting process for a tweet with 6 RT. 
Where the first event occurs after 1.4 minutes.

\begin{center}
	\textit{1.400000    1.616667    1.716667    1.716667    1.900000    2.616667}
\end{center}

Knowing that, as stated in Section 6.7 of Dobrow RP \textit{Introduction to Stochastic Processes with R}, a non-homogeneous Poisson process is a counting process $(N_t)_{t\geq0}$ with intensity function $\lambda(t)$ if
\begin{itemize}
	\item $N_0 = 0$ 
	\item For all $t>0$, $N_t$ has a Poisson distribution with mean
	\[\mathbb{E}[N_t] = \int^t_0\lambda(x)dx\]
	\item For $0\leq q < r \leq s < t$, $N_r - N_q$ and $N_t - N_s$ are independent random variables.
\end{itemize}

We know that the process already satisfies the conditions of a counting process. In order to find if it fits the hypothesis of a Poisson process, knowing that the times are not homogeneous, we will consider a non-homogeneous Poisson process.

When analyzing time frequencies between retweets we notice that the ratio decreases over time (this behaviour can be observed in the (\ref{fig:rtMax}) plot). Meaning that if it were to be a non-homogeneous Poisson process, for all $t>0$, $N_t$ it would follow a Poisson distribution with $\mathbb{E}[N_t] = \lambda = \int_{t}^{0} \lambda(x)dx$ where $\lambda_t < \lambda_{t+1}$ for all $t$ (difference greater over time), assuming unknown intensity function.


\subsection{Assuming you can model the number of retweets by time as a non-homogeneous Poisson process with intensity function $ \lambda (t) = \theta e^{-\theta t},\ t>0$, graphically explore possible values of $\theta$ and choose the one that best fit your data. Explain all the considerations you make.}

In order to find the best $\theta$ possible, we need to simplify the problem. 
The first thing we perform is to find the mean poisson process of the Real Madrid twitter account. 
We can treat this mean poisson process as the expected retweet poisson process of a random tweet written in the Real Madrid account.

Because not all the tweets have the same amount of retweets we cannot calculate directly the mean value for a given time. 
In order to compute such value, first, all tweets times are interpolated to have the same amount of points (the number of points is equal to the number of retweets of the max RT tweet). 
Later, the values can simply be summed and divided by the total number of tweets. Finally, this mean line is scaled to a range $[0, 1]$ for easy computation and visualization along with the $\theta$.
Once we have this mean line, we can plot it along with an arbitrary value of theta and compare visually.

\begin{figure}[H]
	\centering
	\begin{subfigure}{.5\textwidth}
		\centering
		\input{./figures/notAdjustedTheta.tex}
		\caption{Mean RT time of tweets (Red) and \\ Simulated values with arbitrary $\theta$ (Blue)}
		\label{fig:thetaNot}
	\end{subfigure}%
	\begin{subfigure}{.5\textwidth}
		\centering
		\input{./figures/adjustedTheta.tex}
		\caption{Mean RT time of tweets (Red) and \\Simulated values with optimal (Blue)$\theta$}
		\label{fig:thetaYes}
	\end{subfigure}
\end{figure}


Once this two lines are plotted jointly, it is easily to see that an optimal value for $\theta$ would be the one that minimize the area between the two lines. 
That is exactly we did in the right plot. 
We write a function that automatically minimize this area and give us a value of $\theta=0.001683839$ with an area between lines of $173.1745$

\subsection{Write an R function to simulate data from a non-homogeneous Poisson process during a given time interval. Describe the inputs and outputs of your function.}

As stated in section 11.5.1 of Ross, Sheldon \textit{Introduction To Probability Models}, given $n$ events of a non-homogeneous Poisson process by time $T$ (maximum time) the $n$ event times are independent with a common density function
\[f(s) = \frac{\lambda(s)}{\mathbb{E}[N_T]},\ 0<s<T, \quad \mathbb{E}[N_T] = \int^T_0\lambda(s)ds\]
By simulating $N_T$, the number of events by time $T$, and then simulating $N_T$ random variables from the previous density function we can generate a NHPP.

However, this procedure requires on the inverted distribution of $f(s)$  and may be too complex to obtain. Since this is a general function with the aim of simulating any non-homogeneous process we will opt for a rejection method.

That is, we reject or accept values of uniform $(0, T)$ random variables. Defining a limiting $\overline\lambda$, a bound on $\lambda(s), 0\leq s \leq T$, then 
\[\frac{T \lambda(s)}{\mathbb{E}[N_T]} \leq \frac{\overline\lambda T}{\mathbb{E}[N_T]} \]

Therefore, generating random numbers $U_1$ and $U_2$ we accept $U_1T$ if
\[U_2 \leq \frac{\lambda(U_1T)}{\overline \lambda}\]

This $\overline\lambda$ is an arbitrary parameter based on the non-homogeneous Poisson process to be modelled. For the retweet counting process, knowing that the rate at which a retweet occurs decreases over time (most RT occur right after the publication), in order to mimic that behaviour, $\overline\lambda$ needs to be a low value as to reject most of the values at the end of the process.

Translated into the following R function
\begin{minted}{python}
simulateNHPP <- function(intensity_function, time, lambda_bound) {
X <- numeric(0)
  for (t in 1:time){
      u <- runif(2)
      accept <- u[2] <= intensity_function(time*u[1]) / lambda_bound
      if (accept)
          X <- c(X, time * u[1])
   }

  return(sort(X))
}
\end{minted}

The simulation function takes 3 parameters, \textit{intensity\_function}, \textit{time} and \textit{lambda\_bound}. Representing the intensity function of the process to be simulated, a maximum time $t$ to simulate data in the interval $(0, t)$ and an arbitrary $\overline \lambda$ to adjust the simulation.

It returns a list containing all arrival times, from the starting time $t=0$, each one representing one retweet. 

\subsection{Simulate data using the previous function trying to mimic the real retweets data set. Compare the distribution of arrival times for the real and simulated data set. Comment on the differences.}

Using the previously implemented function and having estimated the optimal value for $\theta$ we model our account retweet process. Knowing that the maximum number of retweets is limited by Twitter's API to 100, the following $\overline \lambda=0.01 = \frac{1}{100}$ has been established. This $\overline \lambda$ would vary depending on these maximum retweets.

When running the algorithm we obtain a sequence of arrival times in the interval $(0, T)$ with the following frequency histogram

\begin{figure}[H]
	\centering
	\vspace*{-3.5em}
	\scalebox{.8}{\input{./figures/HistFreq.tex}}
	\vspace*{-1.5em}
	\caption{Frequencies of Simulated Process}
\end{figure}

As expected from the original retweet counts the frequency of a user retweeting is higher after the publication of the tweet. 

\begin{figure}[H]
	\centering
	\begin{subfigure}{.5\textwidth}
		\centering
		\input{./figures/simulated1.tex}
		\caption{First Simulation, $\overline\lambda=0.01$}
		\label{fig:sim1}
	\end{subfigure}%
	\begin{subfigure}{.5\textwidth}
		\centering
		\input{./figures/simulated2.tex}
		\caption{Second Simulation, $\overline\lambda=0.01$}
		\label{fig:sim2}
	\end{subfigure}
\end{figure}

The simulated process behaves similarly to the account being studied. However, this does not represent the behaviour of all tweets, as the potential impact of the tweet and the interest it may generate influences the frequency of times.

\subsection{Using the intensity function of part b), compute the probability that a tweet from this user will get more than 10 retweets in the first hour, and the expected number of retweets of a tweet after 24 hours.}

The expected number of retweets are given by 
\[\mathbb{E}[N_t] = \int^t_0\lambda(x)dx \quad \Longrightarrow \quad \mathbb{E}[N_t] = \int^t_0 \theta e^{-\theta x} dx\]
where the intensity function is $ \lambda (t) = \theta e^{-\theta t},\ t>0$. 

However, when calculating the expected values for the previously defined $\theta = 0.001683839$ we get that $\mathbb{E}[N_t] \in (0,\ 1],\ \forall t>0$. Since the mean retweet process was previously scaled, in order to revert this behaviour, we will use the resulting probability to obtain the following adjusted expectation for $N_t$ while using the same $\overline\lambda = 0.01$ as in the simulation as the scaling factor of the expected retweets. 
\[\mathbb{E}'[N_t] = \frac{1}{\overline\lambda} \times \mathbb{E}[N_t] = \frac{1}{\overline\lambda}\int^t_0 \theta e^{-\theta x} dx\]

Therefore, the expected number of retweets after 24 hours (1440 minutes) would be
\[\mathbb{E}'[N_{1440}] = \frac{1}{\overline\lambda} \times \mathbb{E}[N_{1440}] = \frac{1}{0.01} \times 0.9114979 \sim 91\ retweets \] 

Similarly, the probability of $N_t$ being greater than $k$ is
\[P(N_{t} \geq k) = 1 - \sum_{t=0}^{k}\frac{\mathbb{E}'[N_{t}]^k e^{-\mathbb{E}'[N_{t}]}}{k!}\]
then
\[P(N_{60} \geq 10) = 1 - \sum_{t=0}^{10}\frac{\mathbb{E}'[N_{60}]^k e^{-\mathbb{E}'[N_{60}]}}{k!} = 0.3682237\]

\section{Exercise 2}
\subsection*{Question a}
The process $\bm{X} = \{X_t, \ t\geq 0\}$ is a continuous time Markov chain, as we are told that:
\begin{itemize}
	\item The customers arrive according ot a Poisson distribution with rate $\lambda$.
	\item Service times have an exponential distribution with rate $\mu$.
	\item There is no limit to the number of people in the system at any given time.
\end{itemize}

The \emph{state space} of our process is then $\{0\} \cup \mathbb{N}$. 
To obtain the infinitesimal generator, we observe that if $X_t = i$, then the only two possible transitions are into state $i+1$ if another customer joins the line and to state $i-1$ if a cashier finishes servicing its customer.

We know that the time until a new arrival takes place is just the interarrival time of a Poisson process, so it is exponentially distributed with rate $\lambda$.

The time until a customer is serviced is the minimum between the time it takes cashier $1$ to service its customer and the time it takes cashier $2$ to service theirs. 
This is the minimum of two exponentially distributed random variables, so it is also exponential with rate $\mu + \mu = 2\mu$.
\[
Q = \bordermatrix{% 
	 & 0 & 1 & 2 & 3 & \dots \cr
	0& -\lambda & \lambda  & 0        & 0        & \dots  \cr
	1 & \mu       & -(\lambda+\mu) & \lambda  & 0        & \dots  \cr
	2& 0        & 2\mu        & -(\lambda+2\mu) & \lambda  & \dots  \cr
	3 &0        & 0        & 2\mu        & (-\lambda + 2\mu) & \dots  \cr
	\vdots & \vdots   & \vdots   & \vdots   & \vdots   & \ddots
},
\]
The only rows that are different from the rest are the first and second ones.
In the case of the first one, this is because we can only go from state $X_t = 0$ to $X_{t+1} = 1$ if a customer arrives to the queue, and there is no customer to be serviced so that he can leave the queue.

In the case of the second row, now there is only one customer in the system and so he can only be serviced by a single cashier. This means that the chain will jump to state $0$ with rate $\mu$ if the cashier finishes servicing the customer or to state $2$ with rate $\lambda$ if another customer arrives.

From rows $3$ onwards, there is now at least two customers in the system, and as there are two cashiers the rate at which any one customer exits the system is the minimum between the time it takes the two cashiers to service their customer, which is exponentially distributed with rate $2\mu$ as we have explained previously.
Of course, customers can keep arriving at rate $\lambda$ as there is no limit to the amount of customers in the system.

\subsection*{Question b}
We know from the result in slide 21 of the continuous time Markov chain topic that the stationary distributions satisfies that $\bm{\pi}Q = 0$.
To find the stationary distribution we have to look for $\pi$ such that $\pi_i q_{ij} = \pi_j q_{ji}$.

A general expression for the elements $\pi_k, \ k\geq 1$ in terms of $\pi_0$ is the following:
\[
	\pi_k = \pi_0\left(\frac{\lambda}{\mu}\right)^k \frac{1}{2^{k-1}}
\]

We can obtain an expression for $\pi_0$ from Dobrow 7.6, as this is just a M/M/c queue where we have that
\[
	\pi_0^{-1} = \sum_{k=0}^{c-1} \left(\frac{\lambda}{\mu}\right)^k \frac{1}{k!} + \frac{\lambda / \mu}{c!} \left(\frac{1}{1 - \lambda/c\mu}\right)
\]
So four our case where $c=2$, the sum reduces to:
\[
	\pi_0 = \left(1 + \frac{\lambda}{\mu} + \frac{(\lambda/\mu)^2}{2}\left(\frac{1}{1 - \lambda/2\mu}\right)\right)^{-1}
\]

The long term expected number of people in the system can be obtained from Little's formula, which states that 
\[
	L = \lambda W
\]
Where $L$ is the long term average number of costumers in the system, $W$ is the long term average time of each customer in the system and $\lambda$ is the arrival rate (Dobrow 7.6).

Then, we can obtain the value for $L$ by calculating the expectation of the stationary distribution, as is stated in Dobrow 7.6
\[
	 L = \sum_{k \geq 0} k\pi_k
\]
\subsection*{Question c}
We can see that the only way an overtake can take place is if, once customer $j$ arrives to the queue, there is a customer $i$ being served and a free cashier. 
If there are two free cashiers, customer $j$ has nobody to overtake and if both cashiers are occupied he has to wait until one of them is free (and it does not matter which).

Then, in the case previously described we have that the service time for both customer $j$ and customer $i$ is exponentially distributed. As the exponential distribution is \emph{memoryless}, it does not matter how long customer $i$ has been waiting, as the probability of him being serviced before a given amount of time is the same.

Using the expression introduced in section 2 of \cite{baumann2018number}, we can find the expected number of overtakes as
\[
	\frac{\lambda}{\lambda + 2\mu},
\]
which is the particular expression for a M/M/2 queue like the one in our problem.

\subsection*{Question d}
The following code has been used to simulate the process for a given number of customers $k$.

\begin{listing}[H]
	\inputminted[firstline = 143, lastline = 166]{R}{../main.R}
	\caption{M/M/2 simulation}
	\label{lst:mm2sim}
\end{listing}
The generated exit times for a particular run of the simulation for 20 clients is:  1.4055, 16.1761, 35.5182, 16.8476, 24.2676, 19.0045, 21.4588, 25.0099, 23.4262, 25.6694, 35.5983, 38.0062, 42.7047,
39.5616, 48.4383, 40.1864, 41.2149, 48.9295, 41.5665, 46.4211 (in the relevant time unit).

\subsection*{Question e}
If two customers arrive every five minutes, this implies a rate $\lambda = \frac{2}{5}$ customers per minute. We also have that $\mathbf{E}\left[ \text{Cashier Serving Time}\right] = 4$. Since it is exponentially distributed, it rate has to be then $\mu = \frac{1}{4}$ customers per minute.


\textbf{Probability of overtaking:} We can get an estimate for this probability by calculating a trajectory of the chain, computing the number of overtakes and dividing by the total length of the chain. This has been done in \cref{lst:overtaking-sim}, where we have performed this procedure a large number of times then taken the average in order to obtain a better estimate.
\begin{listing}[H]
	\inputminted[firstline = 175, lastline = 187]{R}{../main.R}
	\caption{Overtaking Simulation}
	\label{lst:overtaking-sim}
\end{listing}
The resulting estimate for the probability of overtaking is $0.4717$.

The result when applying the equation introduced in the solution to question c is $\frac{\lambda}{\lambda + 2\mu} = 0.4444$. This is indeed quite close to our estimate, although not exactly the same due to the random nature of the process.

\textbf{Long Run Average of people in the system:}
In this case what we have done is calculate trajectories for the chain for an increasing number of customers. For each of this trajectories we have calculated the mean of the number of customers in the queue, and our final result is the average of the averages, to get a better estimate. The code can be seen in \cref{lst:longrun-sim}.
\begin{listing}[H]
	\inputminted[firstline = 198, lastline = 203]{R}{../main.R}
	\caption{Long Run Average Simulation}
	\label{lst:longrun-sim}
\end{listing}
The estimated average is then $2.2769$, and we can see a plot of the average number of customers in the system in \cref{fig:lravg}.
\begin{figure}[H]
	\centering
	\input{figures/longrunavg.tex}
	\caption{Long run averages}
	\label{fig:lravg}
\end{figure}

The result that we get if we use the calculation expressed in question b has been approximated numerically by R, truncating the sum seen in the solution of question b to 10 terms. The result is then
\[
	L = \sum_{k = 0}^{100} k \pi_k = 10.1330
\]
The result differs quite a bit from the one obtained by the simulation. We have tried to find out the reason for it, but have ultimately been unsuccessful. 
However we think it is likely a failure of either the simulation procedure or the way that we have calculated the average number of customers in the system. 

\printbibliography
\end{document}